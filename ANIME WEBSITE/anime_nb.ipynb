{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep \n",
    "from selenium import webdriver \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "chrome_driver_path = r'C:\\Users\\ELITEBOOK 1030\\Downloads\\chromedriver-win64\\chromedriver.exe'\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://animeheaven.me/search.php?s=demon+slayer\n",
      "Failed to retrieve data from the website.\n",
      "[{'title': 'Demon Slayer: Kimetsu no Yaiba', 'link': 'anime.php?1smbn'}, {'title': 'Demon Slayer: Kimetsu no Yaiba - Mugen Train', 'link': 'anime.php?02a1a'}, {'title': 'Demon Slayer: Kimetsu no Yaiba - Entertainment District Arc', 'link': 'anime.php?nk94m'}, {'title': 'Demon Slayer: Kimetsu no Yaiba - Swordsmith Village Arc', 'link': 'anime.php?z1te2'}, {'title': 'Demon Slayer: Kimetsu no Yaiba - Hashira Training Arc', 'link': 'anime.php?iqvdi'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getname(anime_name):\n",
    "    # Split the anime name into individual words\n",
    "    anime_words = anime_name.split()\n",
    "    \n",
    "    # Join the words with a plus sign (+) as a separator\n",
    "    anime_query = '+'.join(anime_words)\n",
    "    \n",
    "    # Construct the URL template\n",
    "    template = \"https://animeheaven.me/search.php?s={}\"\n",
    "    \n",
    "    # Insert the concatenated query into the URL template\n",
    "    url = template.format(anime_query)\n",
    "    return url\n",
    "\n",
    "a = input(\"ENTER ANIME : \")\n",
    "link = getname(a)\n",
    "print(link)\n",
    "my_list=[]\n",
    "\n",
    "r  = requests.get(link)\n",
    "soup = BeautifulSoup(r.text,'html5lib')\n",
    "let = soup.find_all('div',class_=\"similarname c\")\n",
    "for tag in let:\n",
    " # Find the <a> tag inside the <div> element\n",
    "    tag_a = tag.find('a', href=True)\n",
    "        # Extract the text and href attribute from the <a> tag\n",
    "    if tag_a:\n",
    "        anime_title = tag_a.text.strip()\n",
    "        anime_link = tag_a['href']\n",
    "            # Append the extracted data to the list\n",
    "        my_list.append({'title': anime_title, 'link': anime_link})\n",
    "else:\n",
    "    print(\"Failed to retrieve data from the website.\")\n",
    "\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
